# Advanced optimization
Presentations of the advanced topics in optimization

## Syllabus

1. [Introduction](./01-Intro/01-Intro.pdf)
2. [Gradient descent and beyond. Part 1](./02-FOM/02-FOM.pdf)
3. Stochastic reformulations of basic gradient methods
4. Stochastic methods to train deep neural networks
5. Proximal methods
6. Catalyst and acceleration techniques
7. Universal gradient methods
8. Riemanien optimization
9. Submodular optimization

## Useful links

- [Convex optimization cheatsheet](https://github.com/amkatrutsa/convex_opt/blob/master/notes.pdf), not perfect, but still

