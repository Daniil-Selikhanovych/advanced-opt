# Advanced optimization
Presentations of the advanced topics in optimization

## Syllabus

1. [Introduction](./01-Intro/01-Intro.pdf)
2. [Gradient descent and beyond. Part 1](./02-FOM/02-FOM.pdf)
3. [Stochastic approximation and sample average approximation](./03-SA/Lecture_SA_vs_SAA_.pdf)
4. [Proximal methods](./04-Prox/prox.ipynb)
5. [Mirror descent](./05-MD/05-MD.pdf) + [comparison with projected subgradient method](https://nbviewer.jupyter.org/github/amkatrutsa/advanced-opt/blob/master/05-MD/md_practice.ipynb)
6. Stochastic methods to train deep neural networks
7. Catalyst and acceleration techniques
8. Universal gradient methods
9. Riemanien optimization
10. Submodular optimization

## Useful links

- [Convex optimization cheatsheet](https://github.com/amkatrutsa/convex_opt/blob/master/notes.pdf), not perfect, but still

